{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "mount_file_id": "16qbjHWN_lRXXx_EyFlLZRZ7Um0F0VHqC",
      "authorship_tag": "ABX9TyOULBb4pUb+v5lc3rY6lzbZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimenopea/CachedHE/blob/main/Praxis_Benchmark_2_MPI_Diabetes_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1cDHrQCRin_",
        "outputId": "0939d262-85f6-417f-fb2b-b77b1470a8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin set to manually installed.\n",
            "openmpi-common is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-common set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.16-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting phe\n",
            "  Downloading phe-1.5.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading tenseal-0.3.16-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4442053 sha256=10ec9a45db8f8b6950a16130d3df6159fdce85afc7faeaa4e12b6602553b5451\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: tenseal, phe, mpi4py\n",
            "Successfully installed mpi4py-4.0.3 phe-1.5.0 tenseal-0.3.16\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y openmpi-bin openmpi-common libopenmpi-dev\n",
        "!pip install mpi4py tenseal phe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paillier Uncached"
      ],
      "metadata": {
        "id": "kBnzQ9W5Qon7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_paillier_uncached.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from phe import paillier\n",
        "import os\n",
        "import csv\n",
        "\n",
        "VERSION = 'Paillier PHE Uncached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_paillier_uncached.csv'\n",
        "\n",
        "\n",
        "def init_csv(path):\n",
        "    \"\"\"Create a new CSV file with headers only.\"\"\"\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "def write_csv(path, version, cores, enc_time, inf_time, result):\n",
        "    \"\"\"Append a new row to the existing CSV file.\"\"\"\n",
        "    with open(path, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            version,\n",
        "            cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            result\n",
        "        ])\n",
        "\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, public_key):\n",
        "    \"\"\"\n",
        "    Distributes the encryption of the input vector among processes in the subcommunicator.\n",
        "    Each process encrypts those features whose index modulo the subcommunicator size equals its rank.\n",
        "    The resulting (index, ciphertext) pairs are gathered at the subcommunicator's root,\n",
        "    sorted by index, and reassembled into the complete encrypted input vector.\n",
        "    Returns the total encryption time and the ordered list of encrypted features.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "\n",
        "    # Round-robin distribution: assign indices where index mod size equals rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        # Encrypt the i-th feature.\n",
        "        ct = public_key.encrypt(int(input_vector[i]))\n",
        "        local_encrypted.append((i, ct))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    # Gather all (index, ciphertext) pairs to the root of the subcommunicator.\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_list = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_list.sort(key=lambda x: x[0])\n",
        "        encrypted_vector = [ct for idx, ct in flat_list]\n",
        "    else:\n",
        "        encrypted_vector = None\n",
        "    # Broadcast the complete encrypted vector to all processes in the subcommunicator.\n",
        "    encrypted_vector = sub_comm.bcast(encrypted_vector, root=0)\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, private_key):\n",
        "    \"\"\"\n",
        "    Performs homomorphic model inference on the encrypted input vector.\n",
        "    Each process computes, for its assigned indices, the weighted encryption by multiplying\n",
        "    the encrypted feature by its corresponding weight. These (index, ciphertext) pairs are\n",
        "    gathered, sorted, and then combined via simple sequential addition to compute the homomorphic dot product.\n",
        "    Returns the inference time and the decrypted result.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "\n",
        "    # Distribute the weighted multiplication work (round-robin).\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        # Multiply the encrypted feature by the weight.\n",
        "        ct_weighted = encrypted_vector[i] * weights[i]\n",
        "        local_results.append((i, ct_weighted))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "\n",
        "    total_inference_time = MPI.Wtime() - start_time\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_results = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_results.sort(key=lambda x: x[0])\n",
        "        weighted_cts = [ct for idx, ct in flat_results]\n",
        "\n",
        "        # Simple sequential addition instead of radix sum\n",
        "        final_ciphertext = weighted_cts[0]\n",
        "        for ct in weighted_cts[1:]:\n",
        "            final_ciphertext = final_ciphertext + ct\n",
        "\n",
        "        # Decrypt the final ciphertext to obtain the dot product.\n",
        "        inference_result = private_key.decrypt(final_ciphertext)\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_inference_time, inference_result\n",
        "\n",
        "def run_experiment(exp_cores, input_vector, weights, public_key, private_key, world_comm):\n",
        "    rank = world_comm.Get_rank()\n",
        "\n",
        "    # Create subcommunicator\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, public_key)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, private_key)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\", flush=True)\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\", flush=True)\n",
        "        # Write to CSV\n",
        "        write_csv(CSV_PATH, VERSION, exp_cores, enc_time, inf_time, inference_result)\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    # Initialize CSV file with headers only (overwriting any existing file)\n",
        "    if rank == 0:\n",
        "        init_csv(CSV_PATH)\n",
        "        print(f\"== {VERSION} ==\", flush=True)\n",
        "\n",
        "    # Load data\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "        public_key, private_key = paillier.generate_paillier_keypair(n_length=1024)\n",
        "    else:\n",
        "        input_vector = None\n",
        "        public_key, private_key = None, None\n",
        "\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "    public_key = world_comm.bcast(public_key, root=0)\n",
        "    private_key = world_comm.bcast(private_key, root=0)\n",
        "\n",
        "    weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "\n",
        "    for exp_cores in [4, 8, 16, 32]:\n",
        "        if world_size >= exp_cores:\n",
        "            run_experiment(exp_cores, input_vector, weights, public_key, private_key, world_comm)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\", flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuUGMmgMFShD",
        "outputId": "dd258477-3e84-4b6d-f565-ca5417a85c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_paillier_uncached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paillier Cached"
      ],
      "metadata": {
        "id": "uShMQRhbFwoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_paillier_cached.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from phe import paillier\n",
        "import os\n",
        "import csv\n",
        "\n",
        "VERSION = 'Paillier PHE Cached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_paillier_cached.csv'\n",
        "\n",
        "\n",
        "def init_csv(path):\n",
        "    # Create the CSV with headers - this will overwrite any existing file\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "\n",
        "def write_to_csv(path, data):\n",
        "    # Write all data at once to the CSV\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        # Write the header\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "        # Write all data rows\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "\n",
        "def radix_sum(ciphertexts, radix=2):\n",
        "    \"\"\"\n",
        "    Sums a list of ciphertexts using a tree-based reduction.\n",
        "    Groups the ciphertexts into chunks of size 'radix', homomorphically adds each group,\n",
        "    and repeats until only one ciphertext remains.\n",
        "    \"\"\"\n",
        "    while len(ciphertexts) > 1:\n",
        "        new_ciphertexts = []\n",
        "        for i in range(0, len(ciphertexts), radix):\n",
        "            group = ciphertexts[i:i+radix]\n",
        "            group_sum = group[0]\n",
        "            for ct in group[1:]:\n",
        "                group_sum = group_sum + ct\n",
        "            new_ciphertexts.append(group_sum)\n",
        "        ciphertexts = new_ciphertexts\n",
        "    return ciphertexts[0]\n",
        "\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, public_key):\n",
        "    \"\"\"\n",
        "    Distributes the encryption of the input vector among processes in the subcommunicator.\n",
        "    Each process encrypts those features whose index modulo the subcommunicator size equals its rank.\n",
        "    The resulting (index, ciphertext) pairs are gathered at the subcommunicator's root,\n",
        "    sorted by index, and reassembled into the complete encrypted input vector.\n",
        "    Returns the total encryption time and the ordered list of encrypted features.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "\n",
        "    # Round-robin distribution: assign indices where index mod size equals rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        # Encrypt the i-th feature.\n",
        "        ct = public_key.encrypt(int(input_vector[i]))\n",
        "        local_encrypted.append((i, ct))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    # Gather all (index, ciphertext) pairs to the root of the subcommunicator.\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_list = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_list.sort(key=lambda x: x[0])\n",
        "        encrypted_vector = [ct for idx, ct in flat_list]\n",
        "    else:\n",
        "        encrypted_vector = None\n",
        "    # Broadcast the complete encrypted vector to all processes in the subcommunicator.\n",
        "    encrypted_vector = sub_comm.bcast(encrypted_vector, root=0)\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, private_key):\n",
        "    \"\"\"\n",
        "    Performs homomorphic model inference on the encrypted input vector.\n",
        "    Each process computes, for its assigned indices, the weighted encryption by multiplying\n",
        "    the encrypted feature by its corresponding weight. These (index, ciphertext) pairs are\n",
        "    gathered, sorted, and then combined via a tree-based (radix) reduction to compute the homomorphic dot product.\n",
        "    Returns the inference time and the decrypted result.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "\n",
        "    # Distribute the weighted multiplication work (round-robin).\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        # Multiply the encrypted feature by the weight.\n",
        "        ct_weighted = encrypted_vector[i] * weights[i]\n",
        "        local_results.append((i, ct_weighted))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "\n",
        "    total_inference_time = MPI.Wtime() - start_time\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_results = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_results.sort(key=lambda x: x[0])\n",
        "        weighted_cts = [ct for idx, ct in flat_results]\n",
        "        # Use radix caching (tree-based reduction) to sum the ciphertexts.\n",
        "        final_ciphertext = radix_sum(weighted_cts, radix=2)\n",
        "        # Decrypt the final ciphertext to obtain the dot product.\n",
        "        inference_result = private_key.decrypt(final_ciphertext)\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_inference_time, inference_result\n",
        "\n",
        "\n",
        "def run_experiment(exp_cores, input_vector, weights, public_key, private_key, world_comm, results):\n",
        "    rank = world_comm.Get_rank()\n",
        "\n",
        "    # Create subcommunicator\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, public_key)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, private_key)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\", flush=True)\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\", flush=True)\n",
        "        # Store results in the list\n",
        "        results.append([\n",
        "            VERSION,\n",
        "            exp_cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            inference_result\n",
        "        ])\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    # Initialize results list to collect all results\n",
        "    results = []\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f\"== {VERSION} ==\", flush=True)\n",
        "\n",
        "    # Load data\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "        public_key, private_key = paillier.generate_paillier_keypair(n_length=1024)\n",
        "    else:\n",
        "        input_vector = None\n",
        "        public_key, private_key = None, None\n",
        "\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "    public_key = world_comm.bcast(public_key, root=0)\n",
        "    private_key = world_comm.bcast(private_key, root=0)\n",
        "\n",
        "    weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "\n",
        "    for exp_cores in [4, 8, 16, 32]:\n",
        "        if world_size >= exp_cores:\n",
        "            run_experiment(exp_cores, input_vector, weights, public_key, private_key, world_comm, results)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\", flush=True)\n",
        "\n",
        "    # Write all results to CSV at once (only from rank 0)\n",
        "    if rank == 0:\n",
        "        write_to_csv(CSV_PATH, results)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVpFq5tKSQN5",
        "outputId": "9dc02c67-38bb-4133-ceca-a525cd7abbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_paillier_cached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BFV Uncached"
      ],
      "metadata": {
        "id": "6DrhO-xrRfJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_bfv_uncached.py\n",
        "from mpi4py import MPI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import tenseal as ts\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Constants\n",
        "VERSION = 'BFV TenSEAL Uncached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_bfv_uncached.csv'\n",
        "\n",
        "# CSV helpers\n",
        "def write_csv_header(path):\n",
        "    \"\"\"Create a new CSV file with header row, overwriting any existing file\"\"\"\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "def write_csv_row(path, version, cores, enc_time, inf_time, result):\n",
        "    \"\"\"Append a row to the existing CSV file\"\"\"\n",
        "    with open(path, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            version,\n",
        "            cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            result\n",
        "        ])\n",
        "\n",
        "# Existing functions\n",
        "def sequential_sum(ciphertexts):\n",
        "    s = ciphertexts[0]\n",
        "    for ct in ciphertexts[1:]:\n",
        "        s = s + ct\n",
        "    return s\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, ctx):\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        ct = ts.bfv_vector(ctx, [int(input_vector[i])])\n",
        "        serialized = ct.serialize()\n",
        "        local_encrypted.append((i, serialized))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat = [pair for sub in gathered for pair in sub]\n",
        "        flat.sort(key=lambda x: x[0])\n",
        "        serialized_vector = [s for idx, s in flat]\n",
        "    else:\n",
        "        serialized_vector = None\n",
        "    serialized_vector = sub_comm.bcast(serialized_vector, root=0)\n",
        "    encrypted_vector = [ts.bfv_vector_from(ctx, s) for s in serialized_vector]\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, ctx):\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        ctw = encrypted_vector[i] * weights[i]\n",
        "        serialized = ctw.serialize()\n",
        "        local_results.append((i, serialized))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat = [pair for sub in gathered for pair in sub]\n",
        "        flat.sort(key=lambda x: x[0])\n",
        "        weighted_cts = [ts.bfv_vector_from(ctx, s) for idx, s in flat]\n",
        "        final_ct = sequential_sum(weighted_cts)\n",
        "        inference_result = final_ct.decrypt()[0]\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_time, inference_result\n",
        "\n",
        "# Modified run_experiment to use new CSV writing functions\n",
        "def run_experiment(exp_cores, input_vector, weights, ctx, world_comm, is_first_run):\n",
        "    rank = world_comm.Get_rank()\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, ctx)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, ctx)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\")\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\")\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\")\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\")\n",
        "\n",
        "        # If this is the first successful run, write the header and first row\n",
        "        # Otherwise just append the row\n",
        "        if is_first_run:\n",
        "            write_csv_header(CSV_PATH)\n",
        "            is_first_run = False\n",
        "        write_csv_row(CSV_PATH, VERSION, exp_cores, enc_time, inf_time, inference_result)\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "    return is_first_run\n",
        "\n",
        "# Main function modified to create new CSV each run\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Always create a new CSV file with headers at the start of each run\n",
        "        write_csv_header(CSV_PATH)\n",
        "        print(f\"== {VERSION} ==\")\n",
        "\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "        weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "        ctx = ts.context(\n",
        "            ts.SCHEME_TYPE.BFV,\n",
        "            poly_modulus_degree=8192,\n",
        "            plain_modulus=1032193\n",
        "        )\n",
        "        serialized_ctx = ctx.serialize(save_secret_key=True)\n",
        "    else:\n",
        "        input_vector = None\n",
        "        weights = None\n",
        "        serialized_ctx = None\n",
        "\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "    weights = world_comm.bcast(weights, root=0)\n",
        "    serialized_ctx = world_comm.bcast(serialized_ctx, root=0)\n",
        "    ctx = ts.context_from(serialized_ctx)\n",
        "\n",
        "    # Track if this is the first successful run\n",
        "    is_first_run = True\n",
        "\n",
        "    for exp_cores in [4, 8, 16, 32]:\n",
        "        if world_size >= exp_cores:\n",
        "            # No need to track first run status anymore since we always recreate the file\n",
        "            run_experiment(exp_cores, input_vector, weights, ctx, world_comm, is_first_run=False)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK0h5mhwVSrT",
        "outputId": "8ec78040-cd5d-4b34-9149-bf10f436bdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_bfv_uncached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BFV Cached"
      ],
      "metadata": {
        "id": "m0-NeVP4dKIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_bfv_cached.py\n",
        "from mpi4py import MPI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import tenseal as ts\n",
        "import os\n",
        "import csv\n",
        "import math\n",
        "\n",
        "# Constants\n",
        "VERSION = 'BFV TenSEAL Cached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_bfv_cached.csv'\n",
        "RADIX = 2  # binary decomposition\n",
        "\n",
        "# CSV helpers\n",
        "def write_csv_header(path):\n",
        "    \"\"\"Write CSV header, overwriting any existing file.\"\"\"\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "def append_csv(path, version, cores, enc_time, inf_time, result):\n",
        "    \"\"\"Append experiment results to CSV file.\"\"\"\n",
        "    with open(path, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            version,\n",
        "            cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            result\n",
        "        ])\n",
        "\n",
        "def radix_encrypt(plaintext, cache):\n",
        "    \"\"\"\n",
        "    Encrypts a value using radix decomposition approach.\n",
        "    Decomposes the plaintext into RADIX-based digits, then\n",
        "    homomorphically adds cached ciphertexts of RADIX^k.\n",
        "    \"\"\"\n",
        "    value = int(plaintext)\n",
        "\n",
        "    # Handle zero case explicitly - create a fresh encryption of zero\n",
        "    if value == 0:\n",
        "        # We can't multiply by 0 directly as it causes a \"transparent ciphertext\" error\n",
        "        # Instead, encrypt 0 directly\n",
        "        return ts.bfv_vector(cache[0].context(), [0])\n",
        "\n",
        "    # Handle negative values\n",
        "    is_negative = value < 0\n",
        "    value = abs(value)\n",
        "\n",
        "    # Initialize result as None\n",
        "    ct = None\n",
        "\n",
        "    # Decompose into radix\n",
        "    k = 0\n",
        "    while value > 0:\n",
        "        digit = value % RADIX\n",
        "        if digit:  # Only process non-zero digits\n",
        "            term = cache[k] * digit\n",
        "            if ct is None:\n",
        "                ct = term\n",
        "            else:\n",
        "                ct = ct + term\n",
        "        value //= RADIX\n",
        "        k += 1\n",
        "\n",
        "    # Apply negative sign if needed\n",
        "    if is_negative and ct is not None:\n",
        "        ct = ct * (-1)\n",
        "\n",
        "    return ct\n",
        "\n",
        "def radix_sum(ciphertexts, radix=2):\n",
        "    \"\"\"\n",
        "    Sums a list of BFVVector objects using a tree-based reduction.\n",
        "    Groups the ciphertexts into chunks of size 'radix', homomorphically adds each group,\n",
        "    and repeats until only one ciphertext remains.\n",
        "    \"\"\"\n",
        "    while len(ciphertexts) > 1:\n",
        "        new_ciphertexts = []\n",
        "        for i in range(0, len(ciphertexts), radix):\n",
        "            group = ciphertexts[i:i+radix]\n",
        "            group_sum = group[0]\n",
        "            for ct in group[1:]:\n",
        "                group_sum = group_sum + ct\n",
        "            new_ciphertexts.append(group_sum)\n",
        "        ciphertexts = new_ciphertexts\n",
        "    return ciphertexts[0]\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, ctx, cache):\n",
        "    \"\"\"\n",
        "    Distributes the encryption of the input vector among processes in the subcommunicator.\n",
        "    Uses the radix encryption approach with the provided cache.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "\n",
        "    # Assign indices round-robin: feature i is handled by process where (i mod size) == rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        # Encrypt using radix decomposition with cache\n",
        "        ct = radix_encrypt(input_vector[i], cache)\n",
        "        # Serialize to a picklable string/bytes object.\n",
        "        serialized = ct.serialize()\n",
        "        local_encrypted.append((i, serialized))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    # Gather all (index, serialized_ciphertext) pairs at the subcommunicator root.\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_list = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_list.sort(key=lambda x: x[0])\n",
        "        # Extract serialized strings.\n",
        "        serialized_vector = [serialized for idx, serialized in flat_list]\n",
        "    else:\n",
        "        serialized_vector = None\n",
        "    # Broadcast the serialized vector (list of strings) to all processes.\n",
        "    serialized_vector = sub_comm.bcast(serialized_vector, root=0)\n",
        "    # Deserialize the list back into BFVVector objects.\n",
        "    encrypted_vector = [ts.bfv_vector_from(ctx, s) for s in serialized_vector]\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, ctx):\n",
        "    \"\"\"\n",
        "    Performs homomorphic model inference on the encrypted input vector.\n",
        "    Each process multiplies its assigned encrypted features by their corresponding weight.\n",
        "    Uses radix sum (tree-based reduction) for better performance.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "\n",
        "    # Distribute work: assign indices where (i mod size) equals rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        # Multiply the encrypted feature by its corresponding weight.\n",
        "        ct_weighted = encrypted_vector[i] * weights[i]\n",
        "        serialized = ct_weighted.serialize()\n",
        "        local_results.append((i, serialized))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "\n",
        "    total_inference_time = MPI.Wtime() - start_time\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_results = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_results.sort(key=lambda x: x[0])\n",
        "        # Deserialize each weighted ciphertext.\n",
        "        weighted_cts = [ts.bfv_vector_from(ctx, s) for idx, s in flat_results]\n",
        "        # Sum the weighted ciphertexts using radix sum (tree-based).\n",
        "        final_ciphertext = radix_sum(weighted_cts, radix=RADIX)\n",
        "        # Decrypt the final ciphertext\n",
        "        inference_result = final_ciphertext.decrypt()[0]\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_inference_time, inference_result\n",
        "\n",
        "def run_experiment(exp_cores, input_vector, weights, ctx, cache, world_comm, results):\n",
        "    \"\"\"\n",
        "    Forms a subcommunicator of size 'exp_cores' from the global communicator and runs:\n",
        "      - Input encryption experiment (using radix-based encryption with cache)\n",
        "      - Model inference experiment (computing the weighted dot product via radix sum)\n",
        "    Timings for both phases are measured and printed from the subcommunicator's root.\n",
        "    Results are collected in the results list for later writing.\n",
        "    \"\"\"\n",
        "    rank = world_comm.Get_rank()\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, ctx, cache)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, ctx)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\", flush=True)\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\", flush=True)\n",
        "        # Store results for later writing\n",
        "        results.append((VERSION, exp_cores, enc_time, inf_time, inference_result))\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    # Store results in a list instead of writing immediately\n",
        "    results = []\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f\"== {VERSION} ==\", flush=True)\n",
        "\n",
        "    # Load the Pima Indian Diabetes dataset on the root using pandas.\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        # Extract the first sample's features (columns 0 to 7).\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "\n",
        "        # Find maximum value to determine cache size\n",
        "        max_val = max(int(x) for x in input_vector)\n",
        "        bits = math.ceil(math.log(max_val+1, RADIX))\n",
        "    else:\n",
        "        input_vector = None\n",
        "        bits = None\n",
        "\n",
        "    # Broadcast the input vector and bits to all processes.\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "    bits = world_comm.bcast(bits, root=0)\n",
        "\n",
        "    # Define predetermined model weights (8 weights).\n",
        "    weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "\n",
        "    # On the root, create a TenSEAL BFV context.\n",
        "    if rank == 0:\n",
        "        ctx = ts.context(\n",
        "            ts.SCHEME_TYPE.BFV,\n",
        "            poly_modulus_degree=8192,\n",
        "            plain_modulus=1032193\n",
        "        )\n",
        "\n",
        "        # Create cache of encrypted powers of RADIX\n",
        "        cache = [ts.bfv_vector(ctx, [RADIX**k]) for k in range(bits+1)]\n",
        "\n",
        "        # Serialize the context with the secret key so that decryption works.\n",
        "        serialized_ctx = ctx.serialize(save_secret_key=True)\n",
        "\n",
        "        # Serialize cache for broadcast\n",
        "        serialized_cache = [c.serialize() for c in cache]\n",
        "    else:\n",
        "        serialized_ctx = None\n",
        "        serialized_cache = None\n",
        "\n",
        "    # Broadcast the serialized context and reconstruct it on all processes.\n",
        "    serialized_ctx = world_comm.bcast(serialized_ctx, root=0)\n",
        "    ctx = ts.context_from(serialized_ctx)\n",
        "\n",
        "    # Broadcast the serialized cache and reconstruct it on all processes\n",
        "    serialized_cache = world_comm.bcast(serialized_cache, root=0)\n",
        "    cache = [ts.bfv_vector_from(ctx, s) for s in serialized_cache]\n",
        "\n",
        "    # Run experiments for subcommunicator sizes: 4, 8, 16, and 32 cores.\n",
        "    experiment_core_counts = [4, 8, 16, 32]\n",
        "    for exp_cores in experiment_core_counts:\n",
        "        if world_size >= exp_cores:\n",
        "            run_experiment(exp_cores, input_vector, weights, ctx, cache, world_comm, results)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\", flush=True)\n",
        "\n",
        "    # Write all results to CSV at once, overwriting the file\n",
        "    if rank == 0:\n",
        "        write_csv_header(CSV_PATH)\n",
        "        for result in results:\n",
        "            append_csv(CSV_PATH, *result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE4FZchTLVF7",
        "outputId": "a9e3a264-2784-4481-9037-bf061397cfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_bfv_cached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CKKS Uncached"
      ],
      "metadata": {
        "id": "-jAaJ33LRmMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_ckks_uncached.py\n",
        "from mpi4py import MPI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import tenseal as ts\n",
        "import math\n",
        "import os\n",
        "import csv\n",
        "\n",
        "VERSION = 'CKKS TenSEAL Uncached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_ckks_uncached.csv'\n",
        "\n",
        "def write_csv_header(path):\n",
        "    \"\"\"Initialize CSV file with headers, overwriting any existing file.\"\"\"\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "def write_csv_row(path, version, cores, enc_time, inf_time, result):\n",
        "    \"\"\"Write experiment results to CSV file.\"\"\"\n",
        "    with open(path, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            version,\n",
        "            cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            result\n",
        "        ])\n",
        "\n",
        "def direct_encrypt(plaintext, ctx):\n",
        "    \"\"\"\n",
        "    Directly encrypts a value using the provided context.\n",
        "    No radix decomposition or caching is used.\n",
        "    \"\"\"\n",
        "    value = float(plaintext)\n",
        "    return ts.ckks_vector(ctx, [value])\n",
        "\n",
        "def sequential_sum(ciphertexts):\n",
        "    \"\"\"\n",
        "    Sums a list of CKKSVector objects sequentially.\n",
        "    Simpler than tree-based reduction but potentially less efficient.\n",
        "    \"\"\"\n",
        "    if not ciphertexts:\n",
        "        return None\n",
        "\n",
        "    result = ciphertexts[0]\n",
        "    for ct in ciphertexts[1:]:\n",
        "        result = result + ct\n",
        "    return result\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, ctx):\n",
        "    \"\"\"\n",
        "    Distributes the encryption of the input vector among processes in the subcommunicator.\n",
        "    Uses direct encryption with no caching.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "\n",
        "    # Assign indices round-robin: feature i is handled by process where (i mod size) == rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        # Directly encrypt the value\n",
        "        ct = direct_encrypt(input_vector[i], ctx)\n",
        "        # Serialize to a picklable string/bytes object.\n",
        "        serialized = ct.serialize()\n",
        "        local_encrypted.append((i, serialized))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    # Gather all (index, serialized_ciphertext) pairs at the subcommunicator root.\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_list = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_list.sort(key=lambda x: x[0])\n",
        "        # Extract serialized strings.\n",
        "        serialized_vector = [serialized for idx, serialized in flat_list]\n",
        "    else:\n",
        "        serialized_vector = None\n",
        "    # Broadcast the serialized vector (list of strings) to all processes.\n",
        "    serialized_vector = sub_comm.bcast(serialized_vector, root=0)\n",
        "    # Deserialize the list back into CKKSVector objects.\n",
        "    encrypted_vector = [ts.ckks_vector_from(ctx, s) for s in serialized_vector]\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, ctx):\n",
        "    \"\"\"\n",
        "    Performs homomorphic model inference on the encrypted input vector.\n",
        "    Each process multiplies its assigned encrypted features by their corresponding weight.\n",
        "    Uses sequential addition rather than tree-based reduction.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "\n",
        "    # Distribute work: assign indices where (i mod size) equals rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        # Multiply the encrypted feature by its corresponding weight.\n",
        "        ct_weighted = encrypted_vector[i] * weights[i]\n",
        "        serialized = ct_weighted.serialize()\n",
        "        local_results.append((i, serialized))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "\n",
        "    total_inference_time = MPI.Wtime() - start_time\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_results = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_results.sort(key=lambda x: x[0])\n",
        "        # Deserialize each weighted ciphertext.\n",
        "        weighted_cts = [ts.ckks_vector_from(ctx, s) for idx, s in flat_results]\n",
        "        # Sum the weighted ciphertexts sequentially\n",
        "        final_ciphertext = sequential_sum(weighted_cts)\n",
        "        # Decrypt the final ciphertext; CKKS decryption returns approximate floats.\n",
        "        inference_result = final_ciphertext.decrypt()[0]\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_inference_time, inference_result\n",
        "\n",
        "def run_experiment(exp_cores, input_vector, weights, ctx, world_comm):\n",
        "    \"\"\"\n",
        "    Forms a subcommunicator of size 'exp_cores' from the global communicator and runs:\n",
        "      - Input encryption experiment (using direct encryption without cache)\n",
        "      - Model inference experiment (computing the weighted dot product via sequential sum)\n",
        "    Timings for both phases are measured and printed from the subcommunicator's root.\n",
        "    \"\"\"\n",
        "    rank = world_comm.Get_rank()\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, ctx)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, ctx)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\", flush=True)\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\", flush=True)\n",
        "        # Write to CSV\n",
        "        write_csv_row(CSV_PATH, VERSION, exp_cores, enc_time, inf_time, inference_result)\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        write_csv_header(CSV_PATH)\n",
        "        print(f\"== {VERSION} ==\", flush=True)\n",
        "\n",
        "    # Load the Pima Indian Diabetes dataset on the root using pandas.\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        # Extract the first sample's features (columns 0 to 7).\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "    else:\n",
        "        input_vector = None\n",
        "\n",
        "    # Broadcast the input vector to all processes.\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "\n",
        "    # Define predetermined model weights (8 weights).\n",
        "    weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "\n",
        "    # On the root, create a TenSEAL CKKS context.\n",
        "    if rank == 0:\n",
        "        ctx = ts.context(\n",
        "            ts.SCHEME_TYPE.CKKS,\n",
        "            poly_modulus_degree=8192,\n",
        "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "        )\n",
        "        ctx.global_scale = 2**40\n",
        "\n",
        "        # Serialize the context with the secret key so that decryption works.\n",
        "        serialized_ctx = ctx.serialize(save_secret_key=True)\n",
        "    else:\n",
        "        serialized_ctx = None\n",
        "\n",
        "    # Broadcast the serialized context and reconstruct it on all processes.\n",
        "    serialized_ctx = world_comm.bcast(serialized_ctx, root=0)\n",
        "    ctx = ts.context_from(serialized_ctx)\n",
        "\n",
        "    # Run experiments for subcommunicator sizes: 4, 8, 16, and 32 cores.\n",
        "    experiment_core_counts = [4, 8, 16, 32]\n",
        "    for exp_cores in experiment_core_counts:\n",
        "        if world_size >= exp_cores:\n",
        "            run_experiment(exp_cores, input_vector, weights, ctx, world_comm)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\", flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-fz-VvaYBda",
        "outputId": "b998c7d9-d450-4642-a75c-d0ac36b2e7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_ckks_uncached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CKKS Cached"
      ],
      "metadata": {
        "id": "qOyhz28EGfy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark2_diabetes_ckks_cached.py\n",
        "from mpi4py import MPI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import tenseal as ts\n",
        "import math\n",
        "import os\n",
        "import csv\n",
        "\n",
        "VERSION = 'CKKS TenSEAL Cached'\n",
        "CSV_PATH = '/content/drive/MyDrive/praxisfiles/Benchmark/benchmark2_diabetes_ckks_cached.csv'\n",
        "RADIX = 2  # binary decomposition\n",
        "\n",
        "def init_csv(path):\n",
        "    \"\"\"Initialize CSV file with headers.\"\"\"\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "\n",
        "def write_to_csv(path, version, cores, enc_time, inf_time, result):\n",
        "    \"\"\"Write experiment results to CSV file.\"\"\"\n",
        "    # Check if file exists and has headers\n",
        "    if not os.path.exists(path):\n",
        "        init_csv(path)\n",
        "\n",
        "    # Read existing data\n",
        "    existing_data = []\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', newline='') as f:\n",
        "            reader = csv.reader(f)\n",
        "            # Skip header\n",
        "            next(reader, None)\n",
        "            # Get all other rows\n",
        "            for row in reader:\n",
        "                existing_data.append(row)\n",
        "\n",
        "    # Update or append new data\n",
        "    updated = False\n",
        "    for i, row in enumerate(existing_data):\n",
        "        if row[0] == version and int(row[1]) == cores:\n",
        "            # Update existing entry\n",
        "            existing_data[i] = [\n",
        "                version,\n",
        "                cores,\n",
        "                f\"{enc_time:.6f}\",\n",
        "                f\"{inf_time:.6f}\",\n",
        "                result\n",
        "            ]\n",
        "            updated = True\n",
        "            break\n",
        "\n",
        "    if not updated:\n",
        "        # Add new entry\n",
        "        existing_data.append([\n",
        "            version,\n",
        "            cores,\n",
        "            f\"{enc_time:.6f}\",\n",
        "            f\"{inf_time:.6f}\",\n",
        "            result\n",
        "        ])\n",
        "\n",
        "    # Write all data back\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        # Write header\n",
        "        writer.writerow([\n",
        "            'Version',\n",
        "            'Cores',\n",
        "            'Input Encryption Time (sec)',\n",
        "            'Model Inference Time (sec)',\n",
        "            'Inference Result (Dot Product)'\n",
        "        ])\n",
        "        # Write data\n",
        "        writer.writerows(existing_data)\n",
        "\n",
        "def radix_encrypt(plaintext, cache):\n",
        "    \"\"\"\n",
        "    Encrypts a value using radix decomposition approach.\n",
        "    Decomposes the plaintext into RADIX-based digits, then\n",
        "    homomorphically adds cached ciphertexts of RADIX^k.\n",
        "    \"\"\"\n",
        "    value = float(plaintext)\n",
        "\n",
        "    # Handle zero case explicitly by directly encrypting 0\n",
        "    if value == 0:\n",
        "        return ts.ckks_vector(cache[0].context(), [0.0])\n",
        "\n",
        "    # Handle negative values\n",
        "    is_negative = value < 0\n",
        "    value = abs(value)\n",
        "\n",
        "    # Integer part\n",
        "    int_value = int(value)\n",
        "\n",
        "    # If the value is zero after all processing, return a fresh encryption of 0\n",
        "    if int_value == 0:\n",
        "        return ts.ckks_vector(cache[0].context(), [0.0])\n",
        "\n",
        "    ct = None\n",
        "    k = 0\n",
        "    while int_value > 0:\n",
        "        digit = int_value % RADIX\n",
        "        if digit:\n",
        "            term = cache[k] * digit\n",
        "            if ct is None:\n",
        "                ct = term\n",
        "            else:\n",
        "                ct = ct + term\n",
        "        int_value //= RADIX\n",
        "        k += 1\n",
        "\n",
        "    # Apply negative sign if needed\n",
        "    if is_negative and ct is not None:\n",
        "        ct = ct * (-1)\n",
        "\n",
        "    # Final safety check to ensure we never return None\n",
        "    if ct is None:\n",
        "        return ts.ckks_vector(cache[0].context(), [0.0])\n",
        "\n",
        "    return ct\n",
        "\n",
        "def radix_sum(ciphertexts, radix=2):\n",
        "    \"\"\"\n",
        "    Sums a list of CKKSVector objects using a tree-based reduction.\n",
        "    Groups the ciphertexts into chunks of size 'radix', homomorphically adds each group,\n",
        "    and repeats until only one ciphertext remains.\n",
        "    \"\"\"\n",
        "    while len(ciphertexts) > 1:\n",
        "        new_ciphertexts = []\n",
        "        for i in range(0, len(ciphertexts), radix):\n",
        "            group = ciphertexts[i:i+radix]\n",
        "            group_sum = group[0]\n",
        "            for ct in group[1:]:\n",
        "                group_sum = group_sum + ct\n",
        "            new_ciphertexts.append(group_sum)\n",
        "        ciphertexts = new_ciphertexts\n",
        "    return ciphertexts[0]\n",
        "\n",
        "def input_encryption_experiment(sub_comm, input_vector, ctx, cache):\n",
        "    \"\"\"\n",
        "    Distributes the encryption of the input vector among processes in the subcommunicator.\n",
        "    Uses the radix encryption approach with the provided cache.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(input_vector)\n",
        "\n",
        "    # Assign indices round-robin: feature i is handled by process where (i mod size) == rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_encrypted = []\n",
        "    for i in indices:\n",
        "        # Encrypt using radix decomposition with cache\n",
        "        ct = radix_encrypt(input_vector[i], cache)\n",
        "        # Serialize to a picklable string/bytes object.\n",
        "        serialized = ct.serialize()\n",
        "        local_encrypted.append((i, serialized))\n",
        "    total_time = MPI.Wtime() - start_time\n",
        "\n",
        "    # Gather all (index, serialized_ciphertext) pairs at the subcommunicator root.\n",
        "    gathered = sub_comm.gather(local_encrypted, root=0)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_list = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_list.sort(key=lambda x: x[0])\n",
        "        # Extract serialized strings.\n",
        "        serialized_vector = [serialized for idx, serialized in flat_list]\n",
        "    else:\n",
        "        serialized_vector = None\n",
        "    # Broadcast the serialized vector (list of strings) to all processes.\n",
        "    serialized_vector = sub_comm.bcast(serialized_vector, root=0)\n",
        "    # Deserialize the list back into CKKSVector objects.\n",
        "    encrypted_vector = [ts.ckks_vector_from(ctx, s) for s in serialized_vector]\n",
        "    return total_time, encrypted_vector\n",
        "\n",
        "def model_inference_experiment(sub_comm, encrypted_vector, weights, ctx):\n",
        "    \"\"\"\n",
        "    Performs homomorphic model inference on the encrypted input vector.\n",
        "    Each process multiplies its assigned encrypted features by their corresponding weight.\n",
        "    Uses radix sum (tree-based reduction) for better performance than sequential addition.\n",
        "    \"\"\"\n",
        "    rank = sub_comm.Get_rank()\n",
        "    size = sub_comm.Get_size()\n",
        "    n_features = len(encrypted_vector)\n",
        "\n",
        "    # Distribute work: assign indices where (i mod size) equals rank.\n",
        "    indices = [i for i in range(n_features) if i % size == rank]\n",
        "\n",
        "    start_time = MPI.Wtime()\n",
        "    local_results = []\n",
        "    for i in indices:\n",
        "        # Multiply the encrypted feature by its corresponding weight.\n",
        "        ct_weighted = encrypted_vector[i] * weights[i]\n",
        "        serialized = ct_weighted.serialize()\n",
        "        local_results.append((i, serialized))\n",
        "    gathered = sub_comm.gather(local_results, root=0)\n",
        "\n",
        "    total_inference_time = MPI.Wtime() - start_time\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        flat_results = [pair for sublist in gathered for pair in sublist]\n",
        "        flat_results.sort(key=lambda x: x[0])\n",
        "        # Deserialize each weighted ciphertext.\n",
        "        weighted_cts = [ts.ckks_vector_from(ctx, s) for idx, s in flat_results]\n",
        "        # Sum the weighted ciphertexts using radix sum (tree-based) instead of sequential.\n",
        "        final_ciphertext = radix_sum(weighted_cts, radix=RADIX)\n",
        "        # Decrypt the final ciphertext; CKKS decryption returns approximate floats.\n",
        "        inference_result = final_ciphertext.decrypt()[0]\n",
        "    else:\n",
        "        inference_result = None\n",
        "    return total_inference_time, inference_result\n",
        "\n",
        "def run_experiment(exp_cores, input_vector, weights, ctx, cache, world_comm):\n",
        "    \"\"\"\n",
        "    Forms a subcommunicator of size 'exp_cores' from the global communicator and runs:\n",
        "      - Input encryption experiment (using radix-based encryption with cache)\n",
        "      - Model inference experiment (computing the weighted dot product via radix sum)\n",
        "    Timings for both phases are measured and printed from the subcommunicator's root.\n",
        "    \"\"\"\n",
        "    rank = world_comm.Get_rank()\n",
        "    if world_comm.Get_size() == exp_cores:\n",
        "        sub_comm = world_comm\n",
        "    else:\n",
        "        color = 0 if rank < exp_cores else MPI.UNDEFINED\n",
        "        sub_comm = world_comm.Split(color, rank)\n",
        "    if sub_comm == MPI.COMM_NULL:\n",
        "        return\n",
        "\n",
        "    enc_time, encrypted_vector = input_encryption_experiment(sub_comm, input_vector, ctx, cache)\n",
        "    inf_time, inference_result = model_inference_experiment(sub_comm, encrypted_vector, weights, ctx)\n",
        "\n",
        "    if sub_comm.Get_rank() == 0:\n",
        "        print(f\"Experiment with {exp_cores} cores:\", flush=True)\n",
        "        print(f\"  Input Encryption Time: {enc_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Model Inference Time:  {inf_time:.6f} sec\", flush=True)\n",
        "        print(f\"  Inference Result (Dot Product): {inference_result}\", flush=True)\n",
        "        # Write to CSV\n",
        "        write_to_csv(CSV_PATH, VERSION, exp_cores, enc_time, inf_time, inference_result)\n",
        "\n",
        "    if sub_comm != world_comm:\n",
        "        sub_comm.Free()\n",
        "\n",
        "def main():\n",
        "    world_comm = MPI.COMM_WORLD\n",
        "    rank = world_comm.Get_rank()\n",
        "    world_size = world_comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        init_csv(CSV_PATH)\n",
        "        print(f\"== {VERSION} ==\", flush=True)\n",
        "\n",
        "    # Load the Pima Indian Diabetes dataset on the root using pandas.\n",
        "    if rank == 0:\n",
        "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "        # Extract the first sample's features (columns 0 to 7).\n",
        "        input_vector = df.iloc[0, :8].tolist()\n",
        "\n",
        "        # Find maximum value to determine cache size\n",
        "        max_val = max(float(x) for x in input_vector)\n",
        "        bits = math.ceil(math.log(max_val+1, RADIX))\n",
        "    else:\n",
        "        input_vector = None\n",
        "        bits = None\n",
        "\n",
        "    # Broadcast the input vector and bits to all processes.\n",
        "    input_vector = world_comm.bcast(input_vector, root=0)\n",
        "    bits = world_comm.bcast(bits, root=0)\n",
        "\n",
        "    # Define predetermined model weights (8 weights).\n",
        "    weights = [2, 1, 3, 1, 1, 2, 1, 1]\n",
        "\n",
        "    # On the root, create a TenSEAL CKKS context.\n",
        "    if rank == 0:\n",
        "        ctx = ts.context(\n",
        "            ts.SCHEME_TYPE.CKKS,\n",
        "            poly_modulus_degree=8192,\n",
        "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "        )\n",
        "        ctx.global_scale = 2**40\n",
        "\n",
        "        # Create cache of encrypted powers of RADIX\n",
        "        cache = [ts.ckks_vector(ctx, [float(RADIX**k)]) for k in range(bits+1)]\n",
        "\n",
        "        # Serialize the context with the secret key so that decryption works.\n",
        "        serialized_ctx = ctx.serialize(save_secret_key=True)\n",
        "\n",
        "        # Serialize cache for broadcast\n",
        "        serialized_cache = [c.serialize() for c in cache]\n",
        "    else:\n",
        "        serialized_ctx = None\n",
        "        serialized_cache = None\n",
        "\n",
        "    # Broadcast the serialized context and reconstruct it on all processes.\n",
        "    serialized_ctx = world_comm.bcast(serialized_ctx, root=0)\n",
        "    ctx = ts.context_from(serialized_ctx)\n",
        "\n",
        "    # Broadcast the serialized cache and reconstruct it on all processes\n",
        "    serialized_cache = world_comm.bcast(serialized_cache, root=0)\n",
        "    cache = [ts.ckks_vector_from(ctx, s) for s in serialized_cache]\n",
        "\n",
        "    # Run experiments for subcommunicator sizes: 4, 8, 16, and 32 cores.\n",
        "    experiment_core_counts = [4, 8, 16, 32]\n",
        "    for exp_cores in experiment_core_counts:\n",
        "        if world_size >= exp_cores:\n",
        "            run_experiment(exp_cores, input_vector, weights, ctx, cache, world_comm)\n",
        "        else:\n",
        "            if rank == 0:\n",
        "                print(f\"Skipping experiment with {exp_cores} cores (world size {world_size} < {exp_cores}).\", flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5IVoWiwEBUI",
        "outputId": "a42091bd-23d4-4a68-d00e-ec817a0ac74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark2_diabetes_ckks_cached.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Experiment"
      ],
      "metadata": {
        "id": "hkygNHPLMi5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_paillier_uncached.py;\n",
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_paillier_cached.py;\n",
        "\n",
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_bfv_uncached.py;\n",
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_bfv_cached.py;\n",
        "\n",
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_ckks_uncached.py\n",
        "!mpirun --allow-run-as-root -np 32 stdbuf -oL python benchmark2_diabetes_ckks_cached.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMh51nD1GjFa",
        "outputId": "b5b397b9-0dcb-4852-8247-dbfc4d4cd994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Paillier PHE Uncached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.035861 sec\n",
            "  Model Inference Time:  0.000144 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.018187 sec\n",
            "  Model Inference Time:  0.000195 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.016047 sec\n",
            "  Model Inference Time:  0.000182 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.016354 sec\n",
            "  Model Inference Time:  0.000211 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "== Paillier PHE Cached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.035480 sec\n",
            "  Model Inference Time:  0.000168 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.017704 sec\n",
            "  Model Inference Time:  0.000184 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.017884 sec\n",
            "  Model Inference Time:  0.000164 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.017539 sec\n",
            "  Model Inference Time:  0.000206 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "== BFV TenSEAL Uncached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.016182 sec\n",
            "  Model Inference Time:  0.011086 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.007375 sec\n",
            "  Model Inference Time:  0.008233 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.007378 sec\n",
            "  Model Inference Time:  0.008136 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.007193 sec\n",
            "  Model Inference Time:  0.019052 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "== BFV TenSEAL Cached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.012881 sec\n",
            "  Model Inference Time:  0.008193 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.003025 sec\n",
            "  Model Inference Time:  0.006850 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.003107 sec\n",
            "  Model Inference Time:  0.005588 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.003020 sec\n",
            "  Model Inference Time:  0.016136 sec\n",
            "  Inference Result (Dot Product): 527\n",
            "== CKKS TenSEAL Uncached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.022020 sec\n",
            "  Model Inference Time:  0.010883 sec\n",
            "  Inference Result (Dot Product): 528.8270709242635\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.009029 sec\n",
            "  Model Inference Time:  0.006459 sec\n",
            "  Inference Result (Dot Product): 528.8270709193511\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.009524 sec\n",
            "  Model Inference Time:  0.005425 sec\n",
            "  Inference Result (Dot Product): 528.8270709275663\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.010517 sec\n",
            "  Model Inference Time:  0.014558 sec\n",
            "  Inference Result (Dot Product): 528.8270709245927\n",
            "== CKKS TenSEAL Cached ==\n",
            "Experiment with 4 cores:\n",
            "  Input Encryption Time: 0.016199 sec\n",
            "  Model Inference Time:  0.006635 sec\n",
            "  Inference Result (Dot Product): 527.0004240540197\n",
            "Experiment with 8 cores:\n",
            "  Input Encryption Time: 0.003703 sec\n",
            "  Model Inference Time:  0.005320 sec\n",
            "  Inference Result (Dot Product): 527.0004240531207\n",
            "Experiment with 16 cores:\n",
            "  Input Encryption Time: 0.003816 sec\n",
            "  Model Inference Time:  0.004767 sec\n",
            "  Inference Result (Dot Product): 527.0004240538134\n",
            "Experiment with 32 cores:\n",
            "  Input Encryption Time: 0.003975 sec\n",
            "  Model Inference Time:  0.009090 sec\n",
            "  Inference Result (Dot Product): 527.0004240534421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_root = '/content/drive/MyDrive/praxisfiles/Benchmark/'"
      ],
      "metadata": {
        "id": "JTsnL2I3ftXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "# Define path root\n",
        "path_root = '/content/drive/MyDrive/praxisfiles/Benchmark/'\n",
        "\n",
        "# Read all CSV files\n",
        "bfv_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_bfv_cached.csv')\n",
        "bfv_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_bfv_uncached.csv')\n",
        "ckks_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_ckks_cached.csv')\n",
        "ckks_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_ckks_uncached.csv')\n",
        "paillier_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_paillier_cached.csv')\n",
        "paillier_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_paillier_uncached.csv')\n",
        "\n",
        "# Define colors for each algorithm\n",
        "colors = {\n",
        "    'BFV': '#1f77b4',\n",
        "    'CKKS': '#ff7f0e',\n",
        "    'Paillier': '#2ca02c'\n",
        "}\n",
        "\n",
        "# Get core values\n",
        "cores = bfv_cached['Cores'].tolist()\n",
        "\n",
        "# Calculate y-axis limits\n",
        "# For encryption time\n",
        "all_encryption_times_cached = pd.concat([\n",
        "    bfv_cached['Input Encryption Time (sec)'],\n",
        "    ckks_cached['Input Encryption Time (sec)'],\n",
        "    paillier_cached['Input Encryption Time (sec)']\n",
        "])\n",
        "\n",
        "all_encryption_times_uncached = pd.concat([\n",
        "    bfv_uncached['Input Encryption Time (sec)'],\n",
        "    ckks_uncached['Input Encryption Time (sec)'],\n",
        "    paillier_uncached['Input Encryption Time (sec)']\n",
        "])\n",
        "\n",
        "min_encryption_time = 0  # Start at 0 for linear scale\n",
        "max_encryption_time_cached = all_encryption_times_cached.max() * 1.1\n",
        "max_encryption_time_uncached = all_encryption_times_uncached.max() * 1.1\n",
        "\n",
        "# Use the same max for both plots for consistency\n",
        "max_encryption_time = max(max_encryption_time_cached, max_encryption_time_uncached)\n",
        "\n",
        "# For inference time\n",
        "all_inference_times_cached = pd.concat([\n",
        "    bfv_cached['Model Inference Time (sec)'],\n",
        "    ckks_cached['Model Inference Time (sec)'],\n",
        "    paillier_cached['Model Inference Time (sec)']\n",
        "])\n",
        "\n",
        "all_inference_times_uncached = pd.concat([\n",
        "    bfv_uncached['Model Inference Time (sec)'],\n",
        "    ckks_uncached['Model Inference Time (sec)'],\n",
        "    paillier_uncached['Model Inference Time (sec)']\n",
        "])\n",
        "\n",
        "min_inference_time = 0  # Start at 0 for linear scale\n",
        "max_inference_time_cached = all_inference_times_cached.max() * 1.1\n",
        "max_inference_time_uncached = all_inference_times_uncached.max() * 1.1\n",
        "\n",
        "# Use the same max for both plots for consistency\n",
        "max_inference_time = max(max_inference_time_cached, max_inference_time_uncached)\n",
        "\n",
        "# Function to create a figure with non-overlapping bars\n",
        "def create_figure(title, datasets, y_column, y_range):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for df, name, color in datasets:\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=df['Cores'],\n",
        "                y=df[y_column],\n",
        "                name=name,\n",
        "                marker_color=color\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        xaxis_title=\"Number of Cores\",\n",
        "        yaxis_title=\"Time (seconds)\",\n",
        "        yaxis=dict(range=y_range),\n",
        "        barmode='group',  # This ensures bars are grouped but not stacked\n",
        "        height=600,\n",
        "        width=800,\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set x-axis to be equally spaced\n",
        "    fig.update_xaxes(\n",
        "        tickmode='array',\n",
        "        tickvals=cores,\n",
        "        ticktext=[str(core) for core in cores],\n",
        "        type='category'  # This ensures equal spacing\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Create figures for encryption time - cached and uncached separate\n",
        "fig_encryption_cached = create_figure(\n",
        "    \"Input Encryption Time - Cached\",\n",
        "    [\n",
        "        (bfv_cached, 'BFV', colors['BFV']),\n",
        "        (ckks_cached, 'CKKS', colors['CKKS']),\n",
        "        (paillier_cached, 'Paillier', colors['Paillier'])\n",
        "    ],\n",
        "    \"Input Encryption Time (sec)\",\n",
        "    [min_encryption_time, max_encryption_time]\n",
        ")\n",
        "\n",
        "fig_encryption_uncached = create_figure(\n",
        "    \"Input Encryption Time - Uncached\",\n",
        "    [\n",
        "        (bfv_uncached, 'BFV', colors['BFV']),\n",
        "        (ckks_uncached, 'CKKS', colors['CKKS']),\n",
        "        (paillier_uncached, 'Paillier', colors['Paillier'])\n",
        "    ],\n",
        "    \"Input Encryption Time (sec)\",\n",
        "    [min_encryption_time, max_encryption_time]\n",
        ")\n",
        "\n",
        "# Create figures for inference time - cached and uncached separate\n",
        "fig_inference_cached = create_figure(\n",
        "    \"Model Inference Time - Cached\",\n",
        "    [\n",
        "        (bfv_cached, 'BFV', colors['BFV']),\n",
        "        (ckks_cached, 'CKKS', colors['CKKS']),\n",
        "        (paillier_cached, 'Paillier', colors['Paillier'])\n",
        "    ],\n",
        "    \"Model Inference Time (sec)\",\n",
        "    [min_inference_time, max_inference_time]\n",
        ")\n",
        "\n",
        "fig_inference_uncached = create_figure(\n",
        "    \"Model Inference Time - Uncached\",\n",
        "    [\n",
        "        (bfv_uncached, 'BFV', colors['BFV']),\n",
        "        (ckks_uncached, 'CKKS', colors['CKKS']),\n",
        "        (paillier_uncached, 'Paillier', colors['Paillier'])\n",
        "    ],\n",
        "    \"Model Inference Time (sec)\",\n",
        "    [min_inference_time, max_inference_time]\n",
        ")\n",
        "\n",
        "# Create a combined view with all four charts\n",
        "fig_combined = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\n",
        "        \"Input Encryption Time - Uncached\",\n",
        "        \"Input Encryption Time - Cached\",\n",
        "        \"Model Inference Time - Uncached\",\n",
        "        \"Model Inference Time - Cached\"\n",
        "    ),\n",
        "    vertical_spacing=0.15,\n",
        "    horizontal_spacing=0.1\n",
        ")\n",
        "\n",
        "# Add traces for encryption time (cached)\n",
        "for df, name, color in [\n",
        "    (bfv_cached, 'BFV', colors['BFV']),\n",
        "    (ckks_cached, 'CKKS', colors['CKKS']),\n",
        "    (paillier_cached, 'Paillier', colors['Paillier'])\n",
        "]:\n",
        "    fig_combined.add_trace(\n",
        "        go.Bar(\n",
        "            x=df['Cores'],\n",
        "            y=df[\"Input Encryption Time (sec)\"],\n",
        "            name=name,\n",
        "            marker_color=color,\n",
        "            showlegend=True\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Add traces for encryption time (uncached)\n",
        "for df, name, color in [\n",
        "    (bfv_uncached, 'BFV', colors['BFV']),\n",
        "    (ckks_uncached, 'CKKS', colors['CKKS']),\n",
        "    (paillier_uncached, 'Paillier', colors['Paillier'])\n",
        "]:\n",
        "    fig_combined.add_trace(\n",
        "        go.Bar(\n",
        "            x=df['Cores'],\n",
        "            y=df[\"Input Encryption Time (sec)\"],\n",
        "            name=name,\n",
        "            marker_color=color,\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# Add traces for inference time (cached)\n",
        "for df, name, color in [\n",
        "    (bfv_cached, 'BFV', colors['BFV']),\n",
        "    (ckks_cached, 'CKKS', colors['CKKS']),\n",
        "    (paillier_cached, 'Paillier', colors['Paillier'])\n",
        "]:\n",
        "    fig_combined.add_trace(\n",
        "        go.Bar(\n",
        "            x=df['Cores'],\n",
        "            y=df[\"Model Inference Time (sec)\"],\n",
        "            name=name,\n",
        "            marker_color=color,\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# Add traces for inference time (uncached)\n",
        "for df, name, color in [\n",
        "    (bfv_uncached, 'BFV', colors['BFV']),\n",
        "    (ckks_uncached, 'CKKS', colors['CKKS']),\n",
        "    (paillier_uncached, 'Paillier', colors['Paillier'])\n",
        "]:\n",
        "    fig_combined.add_trace(\n",
        "        go.Bar(\n",
        "            x=df['Cores'],\n",
        "            y=df[\"Model Inference Time (sec)\"],\n",
        "            name=name,\n",
        "            marker_color=color,\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Update layout for combined figure\n",
        "fig_combined.update_layout(\n",
        "    title_text=\"Homomorphic Encryption Performance Comparison\",\n",
        "    barmode='group',\n",
        "    height=1000,\n",
        "    width=1200,\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=0.9\n",
        "    )\n",
        ")\n",
        "\n",
        "# Update y-axes with fixed ranges to ensure consistency between plots\n",
        "fig_combined.update_yaxes(\n",
        "    title_text=\"Time (seconds)\",\n",
        "    range=[min_encryption_time, max_encryption_time],\n",
        "    row=1, col=1\n",
        ")\n",
        "fig_combined.update_yaxes(\n",
        "    title_text=\"Time (seconds)\",\n",
        "    range=[min_encryption_time, max_encryption_time],\n",
        "    row=1, col=2\n",
        ")\n",
        "fig_combined.update_yaxes(\n",
        "    title_text=\"Time (seconds)\",\n",
        "    range=[min_inference_time, max_inference_time],\n",
        "    row=2, col=1\n",
        ")\n",
        "fig_combined.update_yaxes(\n",
        "    title_text=\"Time (seconds)\",\n",
        "    range=[min_inference_time, max_inference_time],\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Update x-axes with equally spaced core values\n",
        "for row in [1, 2]:\n",
        "    for col in [1, 2]:\n",
        "        fig_combined.update_xaxes(\n",
        "            title_text=\"Number of Cores\",\n",
        "            tickmode='array',\n",
        "            tickvals=cores,\n",
        "            ticktext=[str(core) for core in cores],\n",
        "            type='category',\n",
        "            row=row, col=col\n",
        "        )\n",
        "\n",
        "# Display the figures\n",
        "fig_encryption_uncached.show()\n",
        "fig_encryption_cached.show()\n",
        "\n",
        "fig_inference_uncached.show()\n",
        "fig_inference_cached.show()\n",
        "\n",
        "fig_combined.show()\n",
        "\n",
        "# Optional: Save the figures\n",
        "# fig_encryption_cached.write_html(f\"{path_root}encryption_cached.html\")\n",
        "# fig_encryption_uncached.write_html(f\"{path_root}encryption_uncached.html\")\n",
        "# fig_inference_cached.write_html(f\"{path_root}inference_cached.html\")\n",
        "# fig_inference_uncached.write_html(f\"{path_root}inference_uncached.html\")\n",
        "# fig_combined.write_html(f\"{path_root}combined_comparison.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tDAru3LbfldJ",
        "outputId": "058faa64-88d0-4095-c3c4-760a10f070cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b5611525-93ce-498f-905e-f3b8230bce6c\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b5611525-93ce-498f-905e-f3b8230bce6c\")) {                    Plotly.newPlot(                        \"b5611525-93ce-498f-905e-f3b8230bce6c\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[0.016182,0.007375,0.007378,0.007193],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[0.02202,0.009029,0.009524,0.010517],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[0.035861,0.018187,0.016047,0.016354],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Input Encryption Time - Uncached\"},\"yaxis\":{\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.0394471]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"barmode\":\"group\",\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b5611525-93ce-498f-905e-f3b8230bce6c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2c0bc295-40e3-4bea-afae-f249b997ae0d\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c0bc295-40e3-4bea-afae-f249b997ae0d\")) {                    Plotly.newPlot(                        \"2c0bc295-40e3-4bea-afae-f249b997ae0d\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[0.012881,0.003025,0.003107,0.00302],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[0.016199,0.003703,0.003816,0.003975],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[0.03548,0.017704,0.017884,0.017539],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Input Encryption Time - Cached\"},\"yaxis\":{\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.0394471]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"barmode\":\"group\",\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2c0bc295-40e3-4bea-afae-f249b997ae0d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d197160f-cf35-4fe2-bf44-610fd665cf1a\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d197160f-cf35-4fe2-bf44-610fd665cf1a\")) {                    Plotly.newPlot(                        \"d197160f-cf35-4fe2-bf44-610fd665cf1a\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[0.011086,0.008233,0.008136,0.019052],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[0.010883,0.006459,0.005425,0.014558],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[0.000144,0.000195,0.000182,0.000211],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Model Inference Time - Uncached\"},\"yaxis\":{\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.020957200000000002]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"barmode\":\"group\",\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d197160f-cf35-4fe2-bf44-610fd665cf1a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"fc55df33-ef83-4473-8aa1-cb33baf36b70\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fc55df33-ef83-4473-8aa1-cb33baf36b70\")) {                    Plotly.newPlot(                        \"fc55df33-ef83-4473-8aa1-cb33baf36b70\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[0.008193,0.00685,0.005588,0.016136],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[0.006635,0.00532,0.004767,0.00909],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[0.000168,0.000184,0.000164,0.000206],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Model Inference Time - Cached\"},\"yaxis\":{\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.020957200000000002]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"barmode\":\"group\",\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fc55df33-ef83-4473-8aa1-cb33baf36b70');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a707e88d-044a-4e5a-abd1-32fca70d9985\" class=\"plotly-graph-div\" style=\"height:1000px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a707e88d-044a-4e5a-abd1-32fca70d9985\")) {                    Plotly.newPlot(                        \"a707e88d-044a-4e5a-abd1-32fca70d9985\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"showlegend\":true,\"x\":[4,8,16,32],\"y\":[0.012881,0.003025,0.003107,0.00302],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"showlegend\":true,\"x\":[4,8,16,32],\"y\":[0.016199,0.003703,0.003816,0.003975],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"showlegend\":true,\"x\":[4,8,16,32],\"y\":[0.03548,0.017704,0.017884,0.017539],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.016182,0.007375,0.007378,0.007193],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.02202,0.009029,0.009524,0.010517],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.035861,0.018187,0.016047,0.016354],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.008193,0.00685,0.005588,0.016136],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.006635,0.00532,0.004767,0.00909],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.000168,0.000184,0.000164,0.000206],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.011086,0.008233,0.008136,0.019052],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.010883,0.006459,0.005425,0.014558],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"showlegend\":false,\"x\":[4,8,16,32],\"y\":[0.000144,0.000195,0.000182,0.000211],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.0394471]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0],\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.0394471]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.020957200000000002]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Number of Cores\"},\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"type\":\"category\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.425],\"title\":{\"text\":\"Time (seconds)\"},\"range\":[0,0.020957200000000002]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Input Encryption Time - Uncached\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Input Encryption Time - Cached\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Inference Time - Uncached\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Model Inference Time - Cached\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Homomorphic Encryption Performance Comparison\"},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":0.9},\"barmode\":\"group\",\"height\":1000,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a707e88d-044a-4e5a-abd1-32fca70d9985');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Define path root\n",
        "path_root = '/content/drive/MyDrive/praxisfiles/Benchmark/'\n",
        "\n",
        "# Read all CSV files\n",
        "bfv_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_bfv_cached.csv')\n",
        "bfv_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_bfv_uncached.csv')\n",
        "ckks_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_ckks_cached.csv')\n",
        "ckks_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_ckks_uncached.csv')\n",
        "paillier_cached = pd.read_csv(f'{path_root}benchmark2_diabetes_paillier_cached.csv')\n",
        "paillier_uncached = pd.read_csv(f'{path_root}benchmark2_diabetes_paillier_uncached.csv')\n",
        "\n",
        "# Define colors for each algorithm\n",
        "colors = {\n",
        "    'BFV': '#1f77b4',\n",
        "    'CKKS': '#ff7f0e',\n",
        "    'Paillier': '#2ca02c'\n",
        "}\n",
        "\n",
        "# Get core values\n",
        "cores = bfv_cached['Cores'].tolist()\n",
        "\n",
        "# Calculate speedup factors for encryption time\n",
        "bfv_encryption_speedup = []\n",
        "ckks_encryption_speedup = []\n",
        "paillier_encryption_speedup = []\n",
        "\n",
        "# Calculate speedup factors for inference time\n",
        "bfv_inference_speedup = []\n",
        "ckks_inference_speedup = []\n",
        "paillier_inference_speedup = []\n",
        "\n",
        "# For each core count\n",
        "for core in cores:\n",
        "    # Get encryption times for each algorithm at this core count\n",
        "    bfv_cached_enc = bfv_cached[bfv_cached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "    bfv_uncached_enc = bfv_uncached[bfv_uncached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "\n",
        "    ckks_cached_enc = ckks_cached[ckks_cached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "    ckks_uncached_enc = ckks_uncached[ckks_uncached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "\n",
        "    paillier_cached_enc = paillier_cached[paillier_cached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "    paillier_uncached_enc = paillier_uncached[paillier_uncached['Cores'] == core]['Input Encryption Time (sec)'].values[0]\n",
        "\n",
        "    # Calculate speedup factor: uncached / cached\n",
        "    bfv_enc_speedup = bfv_uncached_enc / bfv_cached_enc\n",
        "    ckks_enc_speedup = ckks_uncached_enc / ckks_cached_enc\n",
        "    paillier_enc_speedup = paillier_uncached_enc / paillier_cached_enc\n",
        "\n",
        "    bfv_encryption_speedup.append(bfv_enc_speedup)\n",
        "    ckks_encryption_speedup.append(ckks_enc_speedup)\n",
        "    paillier_encryption_speedup.append(paillier_enc_speedup)\n",
        "\n",
        "    # Get inference times for each algorithm at this core count\n",
        "    bfv_cached_inf = bfv_cached[bfv_cached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "    bfv_uncached_inf = bfv_uncached[bfv_uncached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "\n",
        "    ckks_cached_inf = ckks_cached[ckks_cached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "    ckks_uncached_inf = ckks_uncached[ckks_uncached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "\n",
        "    paillier_cached_inf = paillier_cached[paillier_cached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "    paillier_uncached_inf = paillier_uncached[paillier_uncached['Cores'] == core]['Model Inference Time (sec)'].values[0]\n",
        "\n",
        "    # Calculate speedup factor: uncached / cached\n",
        "    bfv_inf_speedup = bfv_uncached_inf / bfv_cached_inf\n",
        "    ckks_inf_speedup = ckks_uncached_inf / ckks_cached_inf\n",
        "    paillier_inf_speedup = paillier_uncached_inf / paillier_cached_inf\n",
        "\n",
        "    bfv_inference_speedup.append(bfv_inf_speedup)\n",
        "    ckks_inference_speedup.append(ckks_inf_speedup)\n",
        "    paillier_inference_speedup.append(paillier_inf_speedup)\n",
        "\n",
        "# Calculate min and max for y-axis scaling\n",
        "min_speedup = 0  # Speedup factor should start at 0\n",
        "max_speedup = max(\n",
        "    max(bfv_encryption_speedup), max(ckks_encryption_speedup), max(paillier_encryption_speedup),\n",
        "    max(bfv_inference_speedup), max(ckks_inference_speedup), max(paillier_inference_speedup)\n",
        ")\n",
        "\n",
        "# Add some padding\n",
        "max_speedup = max_speedup * 1.1  # Add 10% padding\n",
        "\n",
        "# Create speedup figures\n",
        "fig_encryption_speedup = go.Figure()\n",
        "\n",
        "# Add bars for each algorithm (encryption speedup)\n",
        "fig_encryption_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=bfv_encryption_speedup,\n",
        "        name='BFV',\n",
        "        marker_color=colors['BFV']\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_encryption_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=ckks_encryption_speedup,\n",
        "        name='CKKS',\n",
        "        marker_color=colors['CKKS']\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_encryption_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=paillier_encryption_speedup,\n",
        "        name='Paillier',\n",
        "        marker_color=colors['Paillier']\n",
        "    )\n",
        ")\n",
        "\n",
        "# Update layout for encryption speedup\n",
        "fig_encryption_speedup.update_layout(\n",
        "    title_text=\"Input Encryption Time Speedup Factor (Uncached/Cached)\",\n",
        "    xaxis_title=\"Number of Cores\",\n",
        "    yaxis_title=\"Speedup Factor\",\n",
        "    yaxis=dict(range=[min_speedup, max_speedup]),\n",
        "    barmode='group',\n",
        "    height=600,\n",
        "    width=800,\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    # Fix layout to ensure bars span the entire width\n",
        "    xaxis=dict(\n",
        "        type='category',\n",
        "        tickmode='array',\n",
        "        tickvals=cores,\n",
        "        ticktext=[str(core) for core in cores],\n",
        "        # These settings help distribute the bars evenly\n",
        "        rangeslider=dict(visible=False),\n",
        "        # Set wider margins\n",
        "        range=[-0.5, len(cores) - 0.5]\n",
        "    ),\n",
        "    # Make plot area more square-like to better distribute bars\n",
        "    margin=dict(l=80, r=80, t=100, b=80)\n",
        ")\n",
        "\n",
        "# Add a horizontal line at speedup = 1 (no change)\n",
        "fig_encryption_speedup.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=-0.5,\n",
        "    y0=1,\n",
        "    x1=len(cores) - 0.5,\n",
        "    y1=1,\n",
        "    line=dict(\n",
        "        color=\"gray\",\n",
        "        width=1,\n",
        "        dash=\"dash\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create inference speedup figure\n",
        "fig_inference_speedup = go.Figure()\n",
        "\n",
        "# Add bars for each algorithm (inference speedup)\n",
        "fig_inference_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=bfv_inference_speedup,\n",
        "        name='BFV',\n",
        "        marker_color=colors['BFV']\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_inference_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=ckks_inference_speedup,\n",
        "        name='CKKS',\n",
        "        marker_color=colors['CKKS']\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_inference_speedup.add_trace(\n",
        "    go.Bar(\n",
        "        x=cores,\n",
        "        y=paillier_inference_speedup,\n",
        "        name='Paillier',\n",
        "        marker_color=colors['Paillier']\n",
        "    )\n",
        ")\n",
        "\n",
        "# Update layout for inference speedup\n",
        "fig_inference_speedup.update_layout(\n",
        "    title_text=\"Model Inference Time Speedup Factor (Uncached/Cached)\",\n",
        "    xaxis_title=\"Number of Cores\",\n",
        "    yaxis_title=\"Speedup Factor\",\n",
        "    yaxis=dict(range=[min_speedup, max_speedup]),\n",
        "    barmode='group',\n",
        "    height=600,\n",
        "    width=800,\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    # Fix layout to ensure bars span the entire width\n",
        "    xaxis=dict(\n",
        "        type='category',\n",
        "        tickmode='array',\n",
        "        tickvals=cores,\n",
        "        ticktext=[str(core) for core in cores],\n",
        "        # These settings help distribute the bars evenly\n",
        "        rangeslider=dict(visible=False),\n",
        "        # Set wider margins\n",
        "        range=[-0.5, len(cores) - 0.5]\n",
        "    ),\n",
        "    # Make plot area more square-like to better distribute bars\n",
        "    margin=dict(l=80, r=80, t=100, b=80)\n",
        ")\n",
        "\n",
        "# Add a horizontal line at speedup = 1 (no change)\n",
        "fig_inference_speedup.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=-0.5,\n",
        "    y0=1,\n",
        "    x1=len(cores) - 0.5,\n",
        "    y1=1,\n",
        "    line=dict(\n",
        "        color=\"gray\",\n",
        "        width=1,\n",
        "        dash=\"dash\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Display speedup figures\n",
        "fig_encryption_speedup.show()\n",
        "fig_inference_speedup.show()\n",
        "\n",
        "# Print the speedup values for reference\n",
        "print(\"Input Encryption Time Speedup Factor (Uncached/Cached):\")\n",
        "print(\"Number of Cores:\", cores)\n",
        "print(\"BFV:\", [round(x, 2) for x in bfv_encryption_speedup])\n",
        "print(\"CKKS:\", [round(x, 2) for x in ckks_encryption_speedup])\n",
        "print(\"Paillier:\", [round(x, 2) for x in paillier_encryption_speedup])\n",
        "print(\"\\nModel Inference Time Speedup Factor (Uncached/Cached):\")\n",
        "print(\"Number of Cores:\", cores)\n",
        "print(\"BFV:\", [round(x, 2) for x in bfv_inference_speedup])\n",
        "print(\"CKKS:\", [round(x, 2) for x in ckks_inference_speedup])\n",
        "print(\"Paillier:\", [round(x, 2) for x in paillier_inference_speedup])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ICagfQIkesr",
        "outputId": "163c2895-e8fb-432c-adbd-0bfc6b094b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f4ff0884-5778-43ba-8b43-ace9b131d346\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f4ff0884-5778-43ba-8b43-ace9b131d346\")) {                    Plotly.newPlot(                        \"f4ff0884-5778-43ba-8b43-ace9b131d346\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[1.2562689232202469,2.43801652892562,2.3746379143868683,2.3817880794701987],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[1.3593431693314402,2.4382932757223874,2.4958071278825993,2.6457861635220126],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[1.010738444193912,1.0272819701762312,0.8972824871393423,0.9324362848509038],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Input Encryption Time Speedup Factor (Uncached\\u002fCached)\"},\"yaxis\":{\"title\":{\"text\":\"Speedup Factor\"},\"range\":[0,2.910364779874214]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"rangeslider\":{\"visible\":false},\"title\":{\"text\":\"Number of Cores\"},\"type\":\"category\",\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"range\":[-0.5,3.5]},\"margin\":{\"l\":80,\"r\":80,\"t\":100,\"b\":80},\"barmode\":\"group\",\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"color\":\"gray\",\"dash\":\"dash\",\"width\":1},\"type\":\"line\",\"x0\":-0.5,\"x1\":3.5,\"y0\":1,\"y1\":1}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f4ff0884-5778-43ba-8b43-ace9b131d346');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"16245358-1d82-454e-a9ad-3a4d7fdefb4d\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"16245358-1d82-454e-a9ad-3a4d7fdefb4d\")) {                    Plotly.newPlot(                        \"16245358-1d82-454e-a9ad-3a4d7fdefb4d\",                        [{\"marker\":{\"color\":\"#1f77b4\"},\"name\":\"BFV\",\"x\":[4,8,16,32],\"y\":[1.3531063102648602,1.2018978102189781,1.4559770937723693,1.1807139315815567],\"type\":\"bar\"},{\"marker\":{\"color\":\"#ff7f0e\"},\"name\":\"CKKS\",\"x\":[4,8,16,32],\"y\":[1.640241145440844,1.2140977443609022,1.1380323054331865,1.6015401540154013],\"type\":\"bar\"},{\"marker\":{\"color\":\"#2ca02c\"},\"name\":\"Paillier\",\"x\":[4,8,16,32],\"y\":[0.8571428571428572,1.059782608695652,1.1097560975609757,1.0242718446601942],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Model Inference Time Speedup Factor (Uncached\\u002fCached)\"},\"yaxis\":{\"title\":{\"text\":\"Speedup Factor\"},\"range\":[0,2.910364779874214]},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"rangeslider\":{\"visible\":false},\"title\":{\"text\":\"Number of Cores\"},\"type\":\"category\",\"tickmode\":\"array\",\"tickvals\":[4,8,16,32],\"ticktext\":[\"4\",\"8\",\"16\",\"32\"],\"range\":[-0.5,3.5]},\"margin\":{\"l\":80,\"r\":80,\"t\":100,\"b\":80},\"barmode\":\"group\",\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"color\":\"gray\",\"dash\":\"dash\",\"width\":1},\"type\":\"line\",\"x0\":-0.5,\"x1\":3.5,\"y0\":1,\"y1\":1}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('16245358-1d82-454e-a9ad-3a4d7fdefb4d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Encryption Time Speedup Factor (Uncached/Cached):\n",
            "Number of Cores: [4, 8, 16, 32]\n",
            "BFV: [np.float64(1.26), np.float64(2.44), np.float64(2.37), np.float64(2.38)]\n",
            "CKKS: [np.float64(1.36), np.float64(2.44), np.float64(2.5), np.float64(2.65)]\n",
            "Paillier: [np.float64(1.01), np.float64(1.03), np.float64(0.9), np.float64(0.93)]\n",
            "\n",
            "Model Inference Time Speedup Factor (Uncached/Cached):\n",
            "Number of Cores: [4, 8, 16, 32]\n",
            "BFV: [np.float64(1.35), np.float64(1.2), np.float64(1.46), np.float64(1.18)]\n",
            "CKKS: [np.float64(1.64), np.float64(1.21), np.float64(1.14), np.float64(1.6)]\n",
            "Paillier: [np.float64(0.86), np.float64(1.06), np.float64(1.11), np.float64(1.02)]\n"
          ]
        }
      ]
    }
  ]
}